from pathlib import Path
import multiprocessing
import subprocess
import os

# Load the configuration file
configfile: "config.yaml"

# Extract global variables from the config
DBDIR = config["database_dir"]
INFILES = config["sample"]  # This can be a list of files
OUTDIR = config["output_dir"]
API_PARAMS = config["api"]
AAI_PARAMS = config["aai"]
ANI_PARAMS = config["ani"]
NUC_SEARCH = config["nuc_search"]

# Define database paths
PROTDB = f"{DBDIR}/VMR_latest/mmseqs_proteins/mmseqs_proteins"
GENOMEDB = f"{DBDIR}/VMR_latest/mmseqs_genomes/mmseqs_genomes"
PROFDB = f"{DBDIR}/VMR_latest/mmseqs_pprofiles/mmseqs_pprofiles"
INDIR = os.path.dirname(INFILES)

# get fasta metadata
f = subprocess.run(["seqkit", "stats", INFILES], capture_output=True, text=True)

file_stats = dict(zip(f.stdout.split("\n")[0].split(),
f.stdout.split("\n")[1].split()))

if int(file_stats["num_seqs"].replace("," ,"")) <= workflow.cores:
    PRODIGAL_SPLITS = int(file_stats["num_seqs"].replace(",", ""))
else:
    PRODIGAL_SPLITS = workflow.cores

# Function to dynamically generate output files
def generate_outputs(wildcards):
    return f"{OUTDIR}/{wildcards.sample}_genome.m8"


# Function to dynamically generate input files
def generate_inputs(wildcards):
    directory_ = os.path.dirname(INFILES)
    file_name, file_extension = os.path.splitext(os.path.basename(INFILES))
    return os.path.join(directory_, f"{wildcards.sample}{file_extension}")


# Rule to define final output
rule all:
    input:
        expand(f"{OUTDIR}/nuc/{{sample}}_{{ext}}_genome.m8",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/tmp/{{sample}}_{{part}}_{{ext}}.gff",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]],
        part=[str(i).zfill(3) for i in range(1, PRODIGAL_SPLITS+1)]),
        expand(f"{OUTDIR}/prot/{{sample}}_{{ext}}_prot.m8",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/prof/{{sample}}_{{ext}}_prof.m8",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/results/{{sample}}_{{ext}}.tsv",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/prot/{{sample}}_{{ext}}.gff",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/nuc/{{sample}}_{{ext}}_genome_ani.tsv",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/prot/{{sample}}_{{ext}}_prot_aai.tsv",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),
        expand(f"{OUTDIR}/prof/{{sample}}_{{ext}}_prof_api.tsv",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]]),        


# Nucelotide level annotations
rule annot_nuc:
    input:
        f"{INDIR}/{{sample}}.{{ext}}"
    output:
        out=f"{OUTDIR}/nuc/{{sample}}_{{ext}}_genome.m8",
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_annot_nuc.log"
    params:
        db=GENOMEDB,
        tmp=temp(f"{OUTDIR}/tmp/nuc"),
    threads: int(workflow.cores * 0.75)
    run:
        
        if NUC_SEARCH == "mmseqs_blastn":
                shell("""
                mkdir -p {params.tmp}
                mmseqs easy-search {input} {params.db} {output.out} {params.tmp} --threads {threads} -s 7 --search-type 3\
                --format-output query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage &> {log}
                """)
        elif NUC_SEARCH == "mmseqs_tblastx":
                shell("""
                mkdir -p {params.tmp}
                mmseqs easy-search {input} {params.db} {output.out} {params.tmp} --threads {threads} -s 7 --search-type 2\
                --format-output query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage &> {log}
                """)

rule split_fasta:
    input:
        f"{INDIR}/{{sample}}.{{ext}}"
    output:
        ["{OUTDIR}/tmp/{{sample}}.part_{i}.{{ext}}".format(OUTDIR=OUTDIR, i=str(i).zfill(3)) for i in range(1, PRODIGAL_SPLITS+1)]
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_split_fasta.log"
    params:
        out=f"{OUTDIR}/tmp",
        splits=PRODIGAL_SPLITS,

    threads: 4
        
    shell:
        """
        seqkit split2 --by-part {params.splits} --threads {threads} {input} -O {params.out} &> {log}
        """    

# predict proteins
# to do: run multiple instances of prodigal-gv parallaly
rule run_prodigal:
    input:
        f"{OUTDIR}/tmp/{{sample}}.part_{{part}}.{{ext}}"
    output:
        fasta=f"{OUTDIR}/tmp/{{sample}}_{{part}}_{{ext}}.faa",
        gff=f"{OUTDIR}/tmp/{{sample}}_{{part}}_{{ext}}.gff",
    log:
        f"{OUTDIR}/logs/{{sample}}_{{part}}_{{ext}}_run_prodigal.log"

    threads: 1
    shell:
        """
        prodigal-gv -i {input} -a {output.fasta} -o {output.gff} -p meta -f gff &> {log}
        """

rule merge_prodigal:
    input:
        faa=expand(f"{OUTDIR}/tmp/{{sample}}_{{part}}_{{ext}}.faa",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]],
        part=[str(i).zfill(3) for i in range(1, PRODIGAL_SPLITS+1)]),

        gff=expand(f"{OUTDIR}/tmp/{{sample}}_{{part}}_{{ext}}.gff",
        sample=[os.path.splitext(os.path.basename(INFILES))[0]],
        ext=[os.path.basename(INFILES).split(".")[-1]],
        part=[str(i).zfill(3) for i in range(1, PRODIGAL_SPLITS+1)]),
    output:
        faa=f"{OUTDIR}/prot/{{sample}}_{{ext}}.faa",
        gff=f"{OUTDIR}/prot/{{sample}}_{{ext}}.gff",
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_merge_prodigal.log"

    threads: 1
    shell:
        """
        cat {input.gff} 1>> {output.gff} 2>> {log}
        cat {input.faa} 1>> {output.faa} 2>> {log}
        """

# Protein level annotations
rule annot_prot:
    input:
        f"{OUTDIR}/prot/{{sample}}_{{ext}}.faa"
    output:
        out=f"{OUTDIR}/prot/{{sample}}_{{ext}}_prot.m8"
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_annot_prot.log"
    params:
        db=PROTDB,
        tmp=temp(f"{OUTDIR}/tmp/prot"),
    threads: int(workflow.cores * 0.75)
    resources:
        mem='30G'
    shell:
        """ 
        mkdir -p {params.tmp}
        mmseqs easy-search {input} {params.db} {output.out} {params.tmp} --threads {threads} -s 6  --split-memory-limit {resources.mem}\
        --format-output query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage &> {log}
        """

# Profile level annotations
rule annot_prof:
    input:
        f"{OUTDIR}/prot/{{sample}}_{{ext}}.faa"
    output:
        f"{OUTDIR}/prof/{{sample}}_{{ext}}_prof.m8"
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_annot_prof.log"
    params:
        db=PROFDB,
        db_root=DBDIR,
        tmp=temp(f"{OUTDIR}/tmp/prof"),
    threads: int(workflow.cores * 0.75)
    resources:
        mem='30G'
    shell:
        """ 
        mkdir -p {params.tmp}
        mmseqs easy-search {input} {params.db} {output} {params.tmp} --threads {threads} -s 7 --split-memory-limit {resources.mem}\
        --format-output query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage &> {log}
        
        correct_profile_taxinfo.py {params.db_root} {output} &>> {log}
        
        """

# nuc = "/media/ssd/ICTV-TaxonomyChallenge/vcat/testing/combined_fasta/nuc/combined_file_fasta_genome_ani.tsv"
# prot = "/media/ssd/ICTV-TaxonomyChallenge/vcat/testing/combined_fasta/prot/combined_file_fasta_prot_aai.tsv"
# prof = "/media/ssd/ICTV-TaxonomyChallenge/vcat/testing/combined_fasta/prof/combined_file_fasta_prof_api.tsv"
rule cal_ani:
    input:
        f"{OUTDIR}/nuc/{{sample}}_{{ext}}_genome.m8"
    output:
        f"{OUTDIR}/nuc/{{sample}}_{{ext}}_genome_ani.tsv"
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_ani.log"
    params:
        batch = 1000,
        ani = ANI_PARAMS
    shell:
        """
        vcat utils ani -i {input} \
        --header query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage \
        --batch {params.batch} {params.ani} &> {log}
        """

rule cal_aai:
    input:
        m8 = f"{OUTDIR}/prot/{{sample}}_{{ext}}_prot.m8",
        gff = f"{OUTDIR}/prot/{{sample}}_{{ext}}.gff"
    output:
        f"{OUTDIR}/prot/{{sample}}_{{ext}}_prot_aai.tsv"
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_aai.log"
    params:
        batch = 1000,
        aai = AAI_PARAMS,
        db = DBDIR
    shell:
        """
        vcat utils aai -i {input.m8} -g {input.gff} -d {params.db} \
        --header query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage \
        --batch {params.batch} {params.aai} &> {log}
        """

rule cal_api:
    input:
        m8 = f"{OUTDIR}/prof/{{sample}}_{{ext}}_prof.m8",
        gff = f"{OUTDIR}/prot/{{sample}}_{{ext}}.gff"
    output:
        f"{OUTDIR}/prof/{{sample}}_{{ext}}_prof_api.tsv"
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_api.log"
    params:
        batch = 1000,
        api = API_PARAMS,
        db = DBDIR
    shell:
        """
        vcat utils api -i {input.m8} -g {input.gff} -d {params.db}\
        --header query,target,theader,fident,qlen,tlen,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,taxid,taxname,taxlineage \
        --batch {params.batch} {params.api} &> {log}
        """

rule summarize:
    input:
        DATADIR = DBDIR,
        PROF = f"{OUTDIR}/prof/{{sample}}_{{ext}}_prof_api.tsv",
        PROT = f"{OUTDIR}/prot/{{sample}}_{{ext}}_prot_aai.tsv",
        NUC = f"{OUTDIR}/nuc/{{sample}}_{{ext}}_genome_ani.tsv",

    output:
        f"{OUTDIR}/results/{{sample}}_{{ext}}.tsv"
    log:
        f"{OUTDIR}/logs/{{sample}}_{{ext}}_summarize.log"

    threads: int(workflow.cores * 0.75)

    params:
        ani=ANI_PARAMS

    shell:
        """ 
        postprocess.py {input.DATADIR} {input.NUC} {input.PROT} {input.PROF} {output} {params.ani} &> {log}
        
        """

# mmseqs easy-taxonomy {input} {params.db} {params.out} {params.tmp} -e 1e-5 -s 7 --blacklist "" --tax-lineage 1 --search-type 3 >> {log}


